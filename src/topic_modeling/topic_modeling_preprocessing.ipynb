{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bf355b-1821-4d59-9004-b180654c2a7f",
   "metadata": {},
   "source": [
    "# Preparation Notebook for Topic Modelling\n",
    "\n",
    "In this notebook, we will complete all the steps required to create a topic model, which is an automated text labelling technique. You can read more about topic models and their use in Nelson, Lukito and Pruden, and Ganesh and Faggiani. \n",
    "\n",
    "Topic modelling is computationally expensive. Therefore, we will need to effeciently create two files. First, a \"dictionary\", which is a database that has a mapping from a word to a numeric ID. For example, the word \"cat|NOUN\" would be represented in this dictionary as a number, for example, 1253. (This is just an example to give you an idea).\n",
    "\n",
    "Then we need a corpus. Our computers don't really have enough memory (RAM) to look at all the documents in a dataset at a time. So we will represent all the words in each document as a series of numbers. We will generate a MatrixMarket corpus which handles all this for us. \n",
    "\n",
    "After we have created both of these files, we can move on (in this notebook) to <i>training</i> topic models or we can load these files in the main topic modelling notebook and train the topic models there.\n",
    "\n",
    "Note: if you get errors related to modules not being found, you might just have to install a few modules.\n",
    "\n",
    "You need to have a folder of docbins to use this notebook. Use the Corpus Linguistics Notebook to create them if you did not already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748b9f94-f5e8-4c09-97b2-2cd4652031ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from drs_topic_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818dce6-5c4e-4813-99f2-690dbcb16785",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Closely read the code cell below. In it, you will have to put in some variable.\n",
    "\n",
    "Make sure to get the right spaCy model; you can find details where you downloaded the model. \n",
    "\n",
    "As well, pay close attention to the project_save_name and docbins_path variables. You will need to change these as you wish for your project.\n",
    "\n",
    "Finally, as we discussed in class, topic models need a number of topics to be pre-set. For example, you need to tell the model if you want 10 topics or 20. Below you will see a value for ks, which is a list of numbers separated by commas in square brackets, like so:\n",
    "\n",
    "        ks = [10,20,30,40,50]\n",
    "    \n",
    "Just make sure that you enter numbers and no quotation marks. Each k will then create a different topic model, and you can then compare the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881f1b15-623d-4b54-9dd2-fcb7b073e144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Read all the documents and create a few files\n",
    "# Here, you will add in the appropriate information so that the code below will work\n",
    "\n",
    "# spacy_model is the language model you are using; the default value should be correct for most use cases, but make sure to use the name of the model exactly as it is given, which you can find in the model section of spacy.io\n",
    "spacy_model = \"en_core_web_sm\"\n",
    "\n",
    "# project save name is the name of your project and is used to create an easy to read name for the different folders and files the script will create automatically\n",
    "project_save_name = \"anxiety\"\n",
    "\n",
    "#create a folder for the probabilities\n",
    "if os.path.exists(f\"../../intermediate_data/{project_save_name}_topic_models_params\"):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(f\"../../intermediate_data/{project_save_name}_topic_models_params\")\n",
    "    \n",
    "# docbins path is a folder where your docbins are stored\n",
    "docbins_path = f\"../../intermediate_data/{project_save_name}_docbins\"\n",
    "#docbins_path = 'anxiety_docbins'\n",
    "\n",
    "# remove_stopwords is whether or not you want the script to remove \"non-lexical\" words, such as \"the\" or \"and\". Change the value to False if you wish to include these words.\n",
    "remove_stopwords = True \n",
    "\n",
    "# if you want to train a topic model in this notebook directly (rather than the following one), put in your k values here\n",
    "# this must be a list of numbers separated by commas, the default is just an example. You can also just put in one value as long as it is in square brackets, eg. [10] for k=10. \n",
    "ks = list(pd.Series(range(2, 11))) # you should always try multiple k values! this way you can compare models rather than just trust that one worked properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7287e6-7ebc-4f96-8ab4-bb79e90e390b",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Run the following code cells to generate the files needed for the topic model training.\n",
    "\n",
    "Once you have run these cells, you can stop the notebook and quit JupyterLab and Anaconda, or continue to train your topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef4ab8a-d60e-4a38-9b87-5dbe2d7d8ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dictionary. This may take some time...\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_0.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_1.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_2.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_3.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_4.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_5.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_6.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_7.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_8.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_9.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_10.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_11.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_12.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_13.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_14.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_15.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_16.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_17.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_18.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_19.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_20.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_21.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_22.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_23.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_24.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_25.db\n",
      "     Processing docbin:  ../../intermediate_data/anxiety_docbins/anxiety_docbin_26.db\n",
      "Processing corpus. This may take some time...\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_0.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_1.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_2.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_3.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_4.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_5.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_6.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_7.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_8.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_9.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_10.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_11.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_12.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_13.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_14.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_15.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_16.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_17.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_18.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_19.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_20.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_21.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_22.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_23.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_24.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_25.db\n",
      "     Processing docbin: ../../intermediate_data/anxiety_docbins/anxiety_docbin_26.db\n"
     ]
    }
   ],
   "source": [
    "# Here, we do all the preprocessing, which creates some files that store our data in an efficient way for our topic model to run.\n",
    "# You only need to run this once! If you already have an \".lda_dict\" and \".mm\" file, you can move on to the Topic Modelling notebook.\n",
    "# If not, you can run this here, and train your first model in the following step.\n",
    "\n",
    "docbins = generate_docbin_paths(docbin_folder = docbins_path,\n",
    "                                project_save_name = project_save_name)\n",
    "\n",
    "print(\"Processing dictionary. This may take some time...\")\n",
    "\n",
    "dictionary = create_gensim_dictionary(\n",
    "    docbins,\n",
    "    spacy_model = spacy_model,\n",
    "    remove_stopwords = True,\n",
    "    filename = f\"../../intermediate_data/{project_save_name}_topic_models_params/{project_save_name}\"\n",
    ")\n",
    "\n",
    "print(\"Processing corpus. This may take some time...\")\n",
    "\n",
    "corpus = generate_mmcorpus(\n",
    "    docbins,\n",
    "    dictionary,\n",
    "    spacy_model = \"en_core_web_sm\",\n",
    "    remove_stopwords = True,\n",
    "    filename = f\"../../intermediate_data/{project_save_name}_topic_models_params/{project_save_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad86667-1964-4a80-9233-e95934cf25d2",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Optional! You can train the topic model here, or you can go to the Main Topic Modelling Notebook and follow those steps. As well, you don't need to go any further if you are trying to train a Word2Vec model as we just need the corpus and dictionary.\n",
    "\n",
    "This can take a long time, depending on how much data you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd2b80-bcf9-45f2-b0cb-777ef7b046ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we train the topic model. If you want to use the other notebook, you can stop here. there is no need to run this cell.\n",
    "# Before running this cell, double check the values you used for k. Are they what you want? Don't try more than 3 k values the first time you run this, so you know how long it will take\n",
    "# this will try to use as much of your CPU as possible, so be prepared to leave your computer alone for a while, and try to make sure it is connected to a power source\n",
    "\n",
    "print(\"Processing topic models. This will take at least a few minutes for each 'k' or number of topics you selected.\")\n",
    "\n",
    "topic_model_directory = \"./\" + project_save_name + \"_topic_models/\"\n",
    "if os.path.exists(topic_model_directory):\n",
    "    create_topic_model(\n",
    "        corpus,\n",
    "        dictionary,\n",
    "        ks,\n",
    "        project_directory = topic_model_directory\n",
    "    )\n",
    "else:\n",
    "    os.mkdir(topic_model_directory)\n",
    "    create_topic_model(\n",
    "        corpus,\n",
    "        dictionary,\n",
    "        ks,\n",
    "        project_directory = topic_model_directory\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
